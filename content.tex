
Unitary Fermi gas provides a curious case of a strongly-correlated many-body
quantum system where interactions are strong, but all properties of the gas are
interaction-independent. This is simply because (assuming s-wave scattering)
interparticle interactions are described by the so-called scattering length, 
and unitarity means that the scattering length is infinite. In this regime, all
information on the details of interactions drops out of all expressions which 
describe physical properties of the gas. From a theoretical point of view, the unitary regime controls
the crossover between Bardeen-Cooper-Schrieffer superconductor (BCS) and a Bose
gas of tight molecules (BEC). \cite{Eagles:1969, Legett:1980}. 
This way, the unitary gas model relates
to a wide range of physical systems, from lab-produced clouds of ultracold gases at
sub-microkelvin temperatures in magnetic and/or optical traps, to inner crusts of
neutron stars.

\subsubsection{Overview of the computational procedure}

The main computational workhorse of the study \cite{PRL:2006, NJP:2006} is a
Monte Carlo (MC) sampling in a space of (partially resummed) Feynman diagrams. 
(for a review see e.g. \cite{Gull:2011} and references therein). From the
practical point of view this is a Monte Carlo simulation where each elementary
move involves rank-1 updates of certain matrices with sizes of the order of up to
 a few thousand.

Extracting physical results from MC data is a three-stage process. First step is
a series of simulations of finite-size Hubbard clusters with varying temperature
and cluster size, at an approximately fixed value of the filling fraction of the lattice. 

Second, these finite-size data are used for extracting the thermodynamic limit behavior
(i.e., the extrapolation to the inifinite system size) \emph{at a given filling fraction}.

Third, simulations are repeated for a series of filling fractions, and an
extrapolation is made towards the zero filling fraction (which corresponds to 
the continuum limit of the lattice model).

The computational complexity of a single MC simulation is, strictly speaking,
only polynomial: $O(N^3)$ for producing a single independent MC sample. Here $N$ is
proportional to the number of particles in a finite-size system, and the extrapolation
is done towards the $N\to\infty$ limit. In practice, simulations were performed
for up to several hundered particles which was enough to extract the thermodynamic limit.
The total simulations in 2006 took several million CPU hours on a vector Cray X1 machine.
Due to the nature of the computations (the bottleneck being
\texttt{BLAS} level 2  outer products , \texttt{dger}), vector architecture was
extremely beneficial for larger system sizes where the conventional cache-based
CPUs choked out due to the cache size effects.


\subsubsection{Setting up the reproduction exercise}

Redoing the full computation, all three stages of it, is difficult to justify
in both human time and usage of computing resource. Therefore, I resorted to reproducing a
single set of steps 1 and 2 above, i.e. reproducing extraction of thermodynamic
limit behavior at a single value of the filling fraction. Specifically, the scope of the exercise
is set to reproduce Fig.\ 2 of Ref.\ \cite{PRL:2006}, which is meant to display a ``typical''
process. 
 
The first step is to find the code. I happen to have a backup.
There is a folder named \texttt{code} with some 30 versions,
consistently named in a pattern \texttt{mon-date}. (Source control? Never
heard of him.) Sadly, the year did not make it into the naming scheme, and the
development was spread over at least one New Year. 
Various files have helpful ``notes-to-self'' type comments
about subtle algorithmic  tweaks and bugs, fixed or found. I am sure these
comments were very helpful back in 2006. 
One day I am going to use this as an intro slide for the
``source control considered a must'' undergraduate research skills class.

\cite{MCWA}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Three years, we launched ReScience, a new scientific journal aimed at publishing the
replication of existing computational research. Since ReScience published its first
article\supercite{Topalidou:2015}, things have been
going steadily. We are still alive, independent and without a budget. In the
meantime, we have published around 24 articles (mostly in computational
neuroscience \& computational ecology) and the initial
\href{https://rescience-c.github.io/board/}{editorial board} has grown from
around 10 to roughly 100 members (editors and reviewers), we have advertised
ReScience at several conferences worldwide, gave some
interviews\supercite{Science:2018}, and published an article introducing
ReScience in PeerJ~CS\supercite{Rougier:2017}. Based on our
experience\supercite{Rougier:2018} at managing the journal during these three
years, we think that time is ripe for some changes.

\subsubsection{ReScience C \& ReScience X}

The biggest and most visible change we would like to propose is to change the
name of the journal ``ReScience'' in favor of ``ReScience C'' where the C
stands for (c)omputational. This change would be necessary to have consistent
naming with the upcoming creation of the ``ReScience X'' journal that will be
dedicated to e(x)perimental replications and co-directed by E.Roesch
(University of Reading) and N.Rougier (University of Bordeaux). The name
``ReScience'' would then be used for the name of a non-profit organization
(that is yet to be created) for the two journals as well as future journals
(such as the utopian CoScience\supercite{Rougier:2017} or a future and
tentative ``ReScience T'' for theoretical science).


\subsubsection{A new submission process}

The current submission process requires authors to fork, clone and branch the
submission repository in order to write their article and to place code and
data at the relevant places in the forked repository. Once done, authors have
to push their changes and to make a pull request that is considered as a
submission. This process is cumbersome for authors and has induced many
troubles for editors as well once the article is accepted and ready to be
published, mostly because of the complexity of the editing procedure. In order
to make life easier for everyone, we greatly simplified the submission process
for ReScience C and X. Authors are now responsible for getting a DOI for their
code \& data and only have to submit a PDF and a metadata file in a GitHub
issue.
We also provide Python programs that largely automate the subsequent editing
process. We will still archive the submission on Zenodo but this archive will
be made for the final PDF only. However, both the PDF and the Zenodo entry will
contain all associated DOIs (data and code).


\subsubsection{A simplified publishing process}

In ReScience, we have have been using a combination of
\href{https://daringfireball.net/projects/markdown/syntax}{markdown} and
\href{http://pandoc.org/}{pandoc} for producing both the draft and the final
version of all the published articles. This had worked reasonably well until it
started to cause all kind of problems for both authors and editors, especially
with the reference and citation plugins. Consequently, articles will be now
submitted directly in PDF with accompanying metadata in a separate file using
the \href{https://en.wikipedia.org/wiki/YAML}{YAML} format (they were
previously embedded in the markdown file). Once an article has been accepted,
authors will be responsible for updating the metadata and for rebuilding the PDF if
necessary. We could also consider using the
\href{https://github.com/openjournals/whedon}{Whedon} API that helps with automating
most of the editorial tasks for \href{http://joss.theoj.org/}{JOSS} and
\href{http://jose.theoj.org/}{JOSE}. This will most probably require some
tweaking because our publishing pipeline is a bit different.


\subsubsection{A new design}

The combination of markdown and pandoc has also severely limited the layout and
style possibilities for the article template and since we are switching to
\LaTeX, this is the opportunity to propose a new design based on a more elegant
style, using a new font stack\supercite{SourceSerifPro:2014, Roboto:2011,
  SourceCodePro:2012} (you are currently reading it). The goal is to have a
subtle but strong identity with enhanced readability. Considering that articles
will be mostly read on screen (as opposed to printed), we can benefit from a
more ethereal style. Once this design will have stabilized, an
\href{https://www.overleaf.com/}{overleaf} template will be made available for
those without a \TeX~installation. If a \TeX~expert is ready to help review
the template (and possibly rewrite it as a class), their help would be much
welcome and appreciated. The same holds for LibreOffice, Word or Pages, any
template is welcome, just contact us beforehand such that we can coordinate
efforts.


\subsubsection{Editorials, letters and special issues}

ReScience C remains dedicated to the publication of computational replications
but we (i.e., the editorial team) would like to have the opportunity to
publish \emph{editorials} when deemed necessary and to give anyone the
opportunity to write \emph{letters} to the community on a specific topic
related to reproducibility. Both editorials and letters are expected to be 1 or
2 pages long (but no hard limit will be enforced), will be (quickly) peer reviewed,
and will be assigned a DOI. Furthermore, with the advent of reproducibility
hackatons worldwide, we will host {\em special issues} with guest editors (such
as, for example, the organizers of a hackaton) in order to publish the results
and to enhance their discoverability. Each entry will have to go through the
regular open peer-reviewed pipeline.\\


We hope that most readers will agree on the proposed changes such that we can
commit to them in the next few weeks. The review for this editorial is open (as
usual) and anyone can comment on and/or oppose any of the proposed changes. New
ideas are also welcome.
